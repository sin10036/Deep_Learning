{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5Xp0rt-D04R"
   },
   "source": [
    "# Generating Text with an RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "zML59-MTD9Zx",
    "outputId": "b0ec2d5c-8536-4476-edca-c1c16f764169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "import os\n",
    "os.chdir(\"gdrive/My Drive/mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "LcPlad6uEAL3",
    "outputId": "26748e52-b7dc-4302-cf3d-320befed27e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 519.5MB 30kB/s \n",
      "tcmalloc: large alloc 1073750016 bytes == 0x59db2000 @  0x7f056de272a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-0.4.1\n",
      "Collecting unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 7.3MB/s \n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.0.23\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch\n",
    "#!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4M6u7U3XD04S",
    "outputId": "afc72de7-17f3-468f-fe85-656930b88e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYLvLz-fD04W"
   },
   "outputs": [],
   "source": [
    "from rnn.model import RNN\n",
    "from rnn.helpers import time_since\n",
    "from rnn.generate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XhO2NkaD04Z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkMU3hLgD04c"
   },
   "source": [
    "## Data Processing\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "d4ksZYJmD04d",
    "outputId": "465fa758-7618-4474-e0d8-524774126cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 4573338\n",
      "train len:  4116004\n",
      "test len:  457334\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file_path = './shakespeare.txt'\n",
    "file = unidecode.unidecode(open(file_path).read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)\n",
    "\n",
    "# we will leave the last 1/10th of text as test\n",
    "split = int(0.9*file_len)\n",
    "train_text = file[:split]\n",
    "test_text = file[split:]\n",
    "\n",
    "print('train len: ', len(train_text))\n",
    "print('test len: ', len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "07EnT_fJD04g",
    "outputId": "27973bf8-1f3b-495f-ad8b-5eed1857809b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ly?\n",
      "\n",
      "VERNON:\n",
      "So do we.\n",
      "\n",
      "HOTSPUR:\n",
      "His is certain, ours is doubtful.\n",
      "\n",
      "EARL OF WORCESTER:\n",
      "Good cousin, be advised; stir not tonight.\n",
      "\n",
      "VERNON:\n",
      "Do not, my lord.\n",
      "\n",
      "EARL OF DOUGLAS:\n",
      "You do not counsel well:\n",
      "Yo\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk(text):\n",
    "    start_index = random.randint(0, len(text) - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return text[start_index:end_index]\n",
    "\n",
    "print(random_chunk(train_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecDKfrYzD04l"
   },
   "source": [
    "### Input and Target data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PnEc2onsD04m"
   },
   "source": [
    "To make training samples out of the large string of text data, we will be splitting the text into chunks.\n",
    "\n",
    "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEF0L6ccD04n"
   },
   "outputs": [],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string), requires_grad=True).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYsvT3ITD04r"
   },
   "source": [
    "The following function loads a batch of input and target tensors for training. Each sample comes from a random chunk of text. A sample input will consist of all characters *except the last*, while the target wil contain all characters *following the first*. For example: if random_chunk='abc', then input='ab' and target='bc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AyWjWYMJD04s"
   },
   "outputs": [],
   "source": [
    "def load_random_batch(text, chunk_len, batch_size):\n",
    "    input_data = torch.zeros(batch_size, chunk_len).long().to(device)\n",
    "    target = torch.zeros(batch_size, chunk_len).long().to(device)\n",
    "    for i in range(batch_size):\n",
    "        start_index = random.randint(0, len(text) - chunk_len - 1)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = text[start_index:end_index]\n",
    "        input_data[i] = char_tensor(chunk[:-1])\n",
    "        target[i] = char_tensor(chunk[1:])\n",
    "    return input_data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rzi3WuBD04w"
   },
   "source": [
    "# Implement model\n",
    "\n",
    "Your RNN model will take as input the character for step $t_{-1}$ and output a prediction for the next character $t$. The model should consiste of three layers - a linear layer that encodes the input character into an embedded state, an RNN layer (which may itself have multiple layers) that operates on that embedded state and a hidden state, and a decoder layer that outputs the predicted character scores distribution.\n",
    "\n",
    "\n",
    "You must implement your model in the `rnn/model.py` file. You should use a `nn.Embedding` object for the encoding layer, a RNN model like `nn.RNN` or `nn.LSTM`, and a `nn.Linear` layer for the final a predicted character score decoding layer.\n",
    "\n",
    "\n",
    "**TODO:** Implement the model in RNN `rnn/model.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQRB3CGbD04x"
   },
   "source": [
    "# Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time.\n",
    "\n",
    "\n",
    "Note that in the `evaluate` function, every time a prediction is made the outputs are divided by the \"temperature\" argument. Higher temperature values make actions more equally likely giving more \"random\" outputs. Lower temperature values (less than 1) high likelihood options contribute more. A temperature near 0 outputs only the most likely outputs.\n",
    "\n",
    "You may check different temperature values yourself, but we have provided a default which should work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-5bM8sHD04y"
   },
   "outputs": [],
   "source": [
    "def evaluate(rnn, prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = rnn.init_hidden(1, device=device)\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = rnn(prime_input[p].unsqueeze(0).to(device), hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = rnn(inp.unsqueeze(0).to(device), hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRNRyekAD041"
   },
   "source": [
    "# Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsW4HypfD042"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_epochs = 2000\n",
    "hidden_size = 150\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "model_type = 'gru'\n",
    "print_every = 50\n",
    "plot_every = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24hT0QmYD044"
   },
   "outputs": [],
   "source": [
    "def eval_test(rnn, inp, target):\n",
    "    with torch.no_grad():\n",
    "        hidden = rnn.init_hidden(batch_size, device=device)\n",
    "        loss = 0\n",
    "        for c in range(chunk_len):\n",
    "            output, hidden = rnn(inp[:,c], hidden)\n",
    "            loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "    \n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfIsNutmD048"
   },
   "source": [
    "### Train function\n",
    "\n",
    "**TODO**: Fill in the train function. You should initialize a hidden layer representation using your RNN's `init_hidden` function, set the model gradients to zero, and loop over each time step (character) in the input tensor. For each time step compute the output of the of the RNN and compute the loss over the output and the corresponding ground truth time step in `target`. The loss should be averaged over all time steps. Lastly, call backward on the averaged loss and take an optimizer step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iGdjZsYD049"
   },
   "outputs": [],
   "source": [
    "def train(rnn, _input, target, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - rnn: model\n",
    "    - input: input character data tensor of shape (batch_size, chunk_len)\n",
    "    - target: target character data tensor of shape (batch_size, chunk_len)\n",
    "    - optimizer: rnn model optimizer\n",
    "    - criterion: loss function\n",
    "    \n",
    "    Returns:\n",
    "    - loss: computed loss value as python float\n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################\n",
    "    #          YOUR CODE HERE          #\n",
    "    ####################################\n",
    "    loss = 0\n",
    "    hidden = rnn.init_hidden(batch_size, device=device)\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = rnn(_input[:,c], hidden)\n",
    "        loss += criterion(output, target[:,c])\n",
    "\n",
    "    loss /= chunk_len\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #loss = loss.data[0] / chunk_len #####should be loss.data.item()?\n",
    "    \n",
    "    ##########       END      ##########\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4097
    },
    "colab_type": "code",
    "id": "Dr_i7HM5D05C",
    "outputId": "383169b2-145f-4441-8c60-32fd8934d711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2000 epochs...\n",
      "[1m 28s (50 2%) train loss: 2.7492, test_loss: 2.7497]\n",
      "Wher aus gaircih-Klt yr t,\n",
      "\n",
      "HRSA!_Bhte ate ehe, phet irh thm thw bme ainss hey t thome, su yo oll t ue \n",
      "\n",
      "[2m 56s (100 5%) train loss: 2.2808, test_loss: 2.2928]\n",
      "Wh, ouptat olme konthry the wpwin hor th the the an! mat aoor and bass fhand ad to at fone fill wa muc \n",
      "\n",
      "[4m 24s (150 7%) train loss: 2.1200, test_loss: 2.1126]\n",
      "Whith yoursen the king beif I do whal: and distis neralus?\n",
      "\n",
      "YORL:\n",
      "Mutiy besthe the thes, chas groness  \n",
      "\n",
      "[5m 52s (200 10%) train loss: 1.9840, test_loss: 1.9969]\n",
      "Whe, the wery flangering this vanibnement there hite sectese at in fair, Hid we suse feat:\n",
      "And the rei \n",
      "\n",
      "[7m 20s (250 12%) train loss: 1.8851, test_loss: 1.8847]\n",
      "Why lacket, some not the sey\n",
      "God afrent in the too?\n",
      "\n",
      "PARDLUS:\n",
      "I did lovers, whlomoul and here, dear of \n",
      "\n",
      "[8m 49s (300 15%) train loss: 1.8157, test_loss: 1.8281]\n",
      "Why powes ead-there: so thy the mess that serve upon:\n",
      "The do;\n",
      "As are our are so corver am this all sco \n",
      "\n",
      "[10m 17s (350 17%) train loss: 1.7632, test_loss: 1.8000]\n",
      "Wher chartor,\n",
      "Our all chuse sing; my have me,\n",
      "Sir, so dust not thee.\n",
      "\n",
      "HACAR:\n",
      "I do head, my sackan us a \n",
      "\n",
      "[11m 46s (400 20%) train loss: 1.6938, test_loss: 1.7439]\n",
      "Wh-tile you destrent have my hast than him dears of agom, suspet, that found ear natured to our orne t \n",
      "\n",
      "[13m 14s (450 22%) train loss: 1.6791, test_loss: 1.7274]\n",
      "Whing with short\n",
      "King seet still she pride the mantry soul speen and his forest and unseep,\n",
      "And have I \n",
      "\n",
      "[14m 43s (500 25%) train loss: 1.6580, test_loss: 1.6873]\n",
      "Where you, flender.\n",
      "\n",
      "VIUS FRome sterve of reeplan:\n",
      "If you do away of me your too in your not a crown\n",
      "A \n",
      "\n",
      "[16m 12s (550 27%) train loss: 1.6109, test_loss: 1.6607]\n",
      "What destruits:\n",
      "Then go to my man to my will? where with watch him\n",
      "Of it. There's mocker such grace hi \n",
      "\n",
      "[17m 40s (600 30%) train loss: 1.5671, test_loss: 1.6179]\n",
      "When they have of heaven show,\n",
      "The laid of him with him in his devil heaven to you.\n",
      "\n",
      "FLORD:\n",
      "An your se \n",
      "\n",
      "[19m 8s (650 32%) train loss: 1.5599, test_loss: 1.6128]\n",
      "Whou such a spoke of his cannot it forcell.\n",
      "\n",
      "KING HENRY V:\n",
      "Yet be'll be field,\n",
      "To Servick and a vain u \n",
      "\n",
      "[20m 37s (700 35%) train loss: 1.5327, test_loss: 1.6060]\n",
      "What will you, my shall now most,\n",
      "To shall lord, falstor, or amperer\n",
      "Be recupy both the Boold, more yo \n",
      "\n",
      "[22m 5s (750 37%) train loss: 1.5241, test_loss: 1.5559]\n",
      "Which which now, but part last;\n",
      "Our grolent grace demislless in wrain him.\n",
      "\n",
      "GON:\n",
      "That I have state, an \n",
      "\n",
      "[23m 34s (800 40%) train loss: 1.5203, test_loss: 1.5756]\n",
      "What never be jead's reason?\n",
      "I will bear the writh it makes it.\n",
      "\n",
      "DROMIO:\n",
      "Gentleman: Cramness and sound \n",
      "\n",
      "[25m 3s (850 42%) train loss: 1.5146, test_loss: 1.5721]\n",
      "Why that I will be Praised\n",
      "Go that is a falsed of love of it, gentleman:\n",
      "Because strange, be better hi \n",
      "\n",
      "[26m 31s (900 45%) train loss: 1.4977, test_loss: 1.5653]\n",
      "Why the other be how:\n",
      "And when a power and his worfes\n",
      "He's rebelly is a man sumine\n",
      "The as the isself w \n",
      "\n",
      "[28m 0s (950 47%) train loss: 1.4653, test_loss: 1.5551]\n",
      "Why comest and deliver you a book\n",
      "To heart in look on the way, and at tate me\n",
      "Was stushims her heart,  \n",
      "\n",
      "[29m 29s (1000 50%) train loss: 1.4828, test_loss: 1.5389]\n",
      "Wher bearty, let whore\n",
      "You\n",
      "belovely faime intracture of wail one.\n",
      "\n",
      "CRIAN:\n",
      "How lords, I'll not suree th \n",
      "\n",
      "[30m 57s (1050 52%) train loss: 1.4587, test_loss: 1.5196]\n",
      "What there is wish, that I read the this\n",
      "mailon in not stand in an resolcies oft?\n",
      "\n",
      "OTHELLO:\n",
      "He hath su \n",
      "\n",
      "[32m 26s (1100 55%) train loss: 1.4285, test_loss: 1.5272]\n",
      "Wher this cuck in the woman:\n",
      "I have word speak on his sorrow straight and trees?\n",
      "\n",
      "EMARD:\n",
      "Ay, my lord,  \n",
      "\n",
      "[33m 55s (1150 57%) train loss: 1.4848, test_loss: 1.5188]\n",
      "Why foul, go to look'd tormed,\n",
      "In the king!\n",
      "\n",
      "Ford:\n",
      "'Tis newls; no mutty's state.\n",
      "\n",
      "KENT:\n",
      "I be darest to \n",
      "\n",
      "[35m 23s (1200 60%) train loss: 1.4170, test_loss: 1.5305]\n",
      "Whas seal all and move to this crown with deed\n",
      "Of need, the compable to fiendshment,\n",
      "In chomes was not \n",
      "\n",
      "[36m 52s (1250 62%) train loss: 1.4117, test_loss: 1.5096]\n",
      "Whither be springs?\n",
      "To make hither's endired does confess which\n",
      "she dare the receive me to to your spe \n",
      "\n",
      "[38m 20s (1300 65%) train loss: 1.4332, test_loss: 1.5025]\n",
      "Whas they seek me in his will\n",
      "The life.\n",
      "And may bring the Greeks my ear to see another,\n",
      "To have a chan \n",
      "\n",
      "[39m 49s (1350 67%) train loss: 1.4349, test_loss: 1.5085]\n",
      "What, thus then shall dost not stand of our bloody,\n",
      "And an our oaths of prive him for prisoners.\n",
      "\n",
      "LORD \n",
      "\n",
      "[41m 18s (1400 70%) train loss: 1.3867, test_loss: 1.5411]\n",
      "What you\n",
      "makes her led and charge it mercy,\n",
      "But mouthsay loss is no reputation.\n",
      "\n",
      "KING LEAR:\n",
      "I may then \n",
      "\n",
      "[42m 46s (1450 72%) train loss: 1.4106, test_loss: 1.4972]\n",
      "Whis a soxer will\n",
      "Like a man man come on the Dukes that he hath been.\n",
      "I will will husband of the went  \n",
      "\n",
      "[44m 15s (1500 75%) train loss: 1.4220, test_loss: 1.5119]\n",
      "Whiles not stomach:\n",
      "I would bite a man of an old against them maid:\n",
      "I stay'd be thum take his buddled  \n",
      "\n",
      "[45m 44s (1550 77%) train loss: 1.3969, test_loss: 1.4983]\n",
      "What stard should make his melice of love\n",
      "In the words out of this tans patient all the fear\n",
      "In subjec \n",
      "\n",
      "[47m 12s (1600 80%) train loss: 1.4047, test_loss: 1.4990]\n",
      "What this feeling to what stars;\n",
      "While tell us, I will die than the last in the deep\n",
      "shall not be for  \n",
      "\n",
      "[48m 41s (1650 82%) train loss: 1.4281, test_loss: 1.5030]\n",
      "Where then, dost thou should you shall,\n",
      "That you may call this fit on you; if which,\n",
      "And subject you,  \n",
      "\n",
      "[50m 9s (1700 85%) train loss: 1.4058, test_loss: 1.4565]\n",
      "What on Hamberit,\n",
      "And she not have as makes are than being in\n",
      "appear, sir, good welcome, nor so enjoy  \n",
      "\n",
      "[51m 36s (1750 87%) train loss: 1.3823, test_loss: 1.4721]\n",
      "What this deed, not, and blose,\n",
      "With men's sealzest young Ford, you have by it.\n",
      "\n",
      "ANTIPHOLUS OF SYRACUS \n",
      "\n",
      "[53m 4s (1800 90%) train loss: 1.3921, test_loss: 1.4734]\n",
      "Whose you? Appear York one,\n",
      "Peace,\n",
      "Pardon me where you would not swear\n",
      "I' the very choleried us that w \n",
      "\n",
      "[54m 31s (1850 92%) train loss: 1.4009, test_loss: 1.4565]\n",
      "What in this tarry, on sits how\n",
      "England's contrant, or you proppier he for you.\n",
      "\n",
      "TIMON:\n",
      "Nay, and will  \n",
      "\n",
      "[55m 56s (1900 95%) train loss: 1.4252, test_loss: 1.4947]\n",
      "Whis saves the Duke,\n",
      "Because you there is the heads to appear.\n",
      "\n",
      "SILVIA:\n",
      "A faith life of faith before t \n",
      "\n",
      "[57m 23s (1950 97%) train loss: 1.3959, test_loss: 1.4960]\n",
      "What said he beaten too.\n",
      "\n",
      "MACBIATH:\n",
      "Let him prove the experiest than the bose\n",
      "Whom the month, and vill \n",
      "\n",
      "[58m 51s (2000 100%) train loss: 1.3605, test_loss: 1.5001]\n",
      "Wher sent: at here.\n",
      "\n",
      "GRADEIMO:\n",
      "And with slain, you were such a flight,\n",
      "And compleep of his sweet, thou \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_characters, hidden_size, n_characters, model_type=model_type, n_layers=n_layers).to(device)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "test_losses = []\n",
    "loss_avg = 0\n",
    "test_loss_avg = 0\n",
    "\n",
    "\n",
    "print(\"Training for %d epochs...\" % n_epochs)\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(rnn, *load_random_batch(train_text, chunk_len, batch_size), rnn_optimizer, criterion)\n",
    "    loss_avg += loss\n",
    "    \n",
    "    test_loss = eval_test(rnn, *load_random_batch(test_text, chunk_len, batch_size))\n",
    "    test_loss_avg += test_loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) train loss: %.4f, test_loss: %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss, test_loss))\n",
    "        print(generate(rnn, 'Wh', 100, device=device), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        test_losses.append(test_loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        test_loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enQ-GLnzD05F"
   },
   "outputs": [],
   "source": [
    "# save network\n",
    "# torch.save(classifier.state_dict(), './rnn_generator.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avmju_MED05I"
   },
   "source": [
    "# Plot the Training and Test Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "AYAAL51RD05J",
    "outputId": "4300610a-2560-400c-ecf6-0da2f4b452e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4aa1637588>]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcHHWd//FX9T3TM9PTM9NzZGZy\nEr8kJAEJCEGOBBBQcfEARBFBQBRRvFhFWV0QFRdWEa9Vfuuui9eCAooQ7oDockhCAiGBbyB3Mplk\n7qun7/r9UTVhksxkOp2ZqZ7uz/Px6EdXV1V3v6kJn6r+fqvqa5imiRBCiMLicjqAEEKI8SfFXQgh\nCpAUdyGEKEBS3IUQogBJcRdCiALkcTrAkLa2vpxP2wmHS+nqio5nnHEj2XIj2XIj2XIzlbNFIuXG\nSPML4sjd43E7HWFUki03ki03ki03hZitIIq7EEKIfUlxF0KIAiTFXQghCpAUdyGEKEBS3IUQogBJ\ncRdCiAIkxV0IIQpQ3lzElKtVeg++rd0snFHpdBQhhMgbU/7I/aHntvKL+19xOoYQQuSVMY/clVKl\nwK+AOiAA3Ky1fnDY8mXALUAa0MCVwKnAH4B19mprtdafG9fktmCJl2hrH/FkGr83f68yE0KIyZRN\ns8z7gJVa61uVUjOAx4EHhy2/E1imtd6hlPoDcA4QBf6qtT5/3BPvJxT0AdA7kCBSWTLRXyeEEFPC\nmMVda333sJfNwI79Vlmste61p9uAaqziPimO3PYq0a076BlYLMVdCCFsRrZjqCqlngWagHO11gc0\nciulGoC/AScAC4GfAW8CVcBNWuvHD/b5qVTazOUGOZ3zj8a9ZQvrX3idJQsbDvn9QggxxY14V8is\nz5bRWp+klDoG+I1S6mit9d69glKqFvgL8BmtdYdS6g3gJuAeYDbwlFLqCK11YrTPz/l2m6VlVA32\n0rJlN231Zbl9xgSKRMppa+tzOsaIJFtuJFtuJFtuxsoWiZSPOD+bDtXFwB6t9Xat9RqllAeIAHvs\n5RXAw8ANWuvHALTWO4Gh5pyNSqlWoBHYnPV/UZYytfUAJHe0AHPG++OFEGJKyuZUyFOBLwMopeqA\nMqB92PLvA7drrR8ZmqGUulgpdZ09XY91ps3O8Qq9jwaruJu7dk3IxwshxFSUTbPMz4FfKqX+BpQA\n1wAfV0r1AI8CHwfmKqWutNf/HfB74HdKqfMAH3D1wZpkDoenqREAo7V1Ij5eCCGmpGzOlhkEPnqQ\nVfyjzH9fTokOkXuadeTuad8zGV8nhBBTwpS/QpV66wwZf4cUdyGEGDLli3umrg6A0q52sj2tUwgh\nCl0BFHerWSbU10kskXY4jRBC5IcpX9zNsnIS/hLCA130DkxIn60QQkw5U764A8SqaghHu+mR4i6E\nEECBFPdkpI5QtIee3kGnowghRF4oiOKeqavHbWZItMi57kIIAQVS3I1p1umQ6Z0TcxGsEEJMNQVR\n3L3N1lWqZovcgkAIIaBAinuguQkAd5tcyCSEEFAgxd033Tpy98otCIQQAiiQ4m5MmwZAoKPN4SRC\nCJEfCqK402B1qAZ75BYEQggBhVLcq6tJu9yE+7sYiKWcTiOEEI4rjOLuchENVRMe6JKrVIUQgkIp\n7ti3IBjoorc/7nQUIYRwXMEU90RNHb50kuhu6VQVQohsBsguBX6FNQ5qALhZa/3gsOVnAt8F0sBy\nrfXN9vzbgRMBE/i81vrFcU8/zNB93ZPbW+AENZFfJYQQeS+bI/f3ASu11qcBFwI/2G/5j4APAe8E\nzlJKzVdKnQbM1VovAa6w15lY9ohMmV0tE/5VQgiR77IZQ/XuYS+bgR1DL5RSs4FOrfV2+/Vy4Awg\nAvzJfv9rSqmwUqpCa907nuGHczdaxd1o3T1RXyGEEFPGmMV9iFLqWaAJOHfY7HpgeCP3HmAOUAOs\nGja/zV531OIeDpfi8bizjXOAmvlzAPB3thOJlOf8ORMh3/IMJ9lyI9lyI9lyk0u2rIu71vokpdQx\nwG+UUkdrrUe6WsgY5e2jzd+rqyuabZQDRCLlDJSH8QGe3a20tfXl/FnjLRIpz6s8w0m23Ei23Ei2\n3IyVbbTCP2abu1JqsVKqGUBrvQZrhxCxF7dgHZEPabTn7T9/GjCht2wcGku1pEvOlhFCiGw6VE8F\nvgyglKoDyoB2AK31FqBCKTVTKeXBarJ5zH6cb7/nWKBFaz2hu8VMpBaAst4OMhm5BYEQorhl0yzz\nc+CXSqm/ASXANcDHlVI9Wuv7gauB39vr3q213gBsUEqtstvpM/Z7JpbPRzQYIjzQTf9gkoqgb8K/\nUggh8lU2Z8sMAh89yPJngCUjzL/+8KIdumi4hnDbLjYMJKS4CyGKWsFcoQoQr45QFo/S19HjdBQh\nhHBUQRX3ZMS6SjWxXcZSFUIUt4Iq7ma9dcZMaqdcpSqEKG4FVdxd9qAd5q5Wh5MIIYSzCqq4exqt\n4fbce6S4CyGKW0EVd789ULanTQbKFkIUt4Iq7q5pVrNMoFOuUhVCFLeCKu7pWqtDNdjV7nASIYRw\nVkEVd8rKiPsClPd1kkpnnE4jhBCOKaziDvRX1lA10EVfNOl0FCGEcEzBFfdYVYRQtIfentxvISyE\nEFNdwRX3RHUtLkwGd8iFTEKI4lVwxT29d6BsuQWBEKJ4FVxxxx60I9MqFzIJIYpXwRV3t32uO3IL\nAiFEESu44u6zr1J179ntcBIhhHBOwRX3oVsQ+DvkFgRCiOKVzTB7KKVuBU6x179Fa32fPb8R+O2w\nVWcD1wM+4GZgoz3/ca31d8Yr9EHVWzcPK5FbEAghitiYxV0ptQxYoLVeopSqBlYD9wForXcCS+31\nPMDTwANYg2PfrbW+bmJij84Mh0m73AR7Oib7q4UQIm9k0yzzDHCBPd0NBJVS7hHWuwy4V2vdP07Z\ncuNy0VdRRai/k2Qq7WgUIYRwimGaZtYrK6WuAk7RWl8ywrLngbO01r1KqcuAa4AOwAtcp7VefbDP\nTqXSpscz0j7j0O2acxQ1WzfQtbub2urguHymEELkKWOkmVm1uQMopc4DrgDOGmHZEuB1rXWvPet5\noE1r/ZC97C5g4cE+v6sr99sFRCLltLX17X0dC0fwblrP1nWbMObNzPlzx8P+2fKJZMuNZMuNZMvN\nWNkikfIR52d1toxS6mzgBuDdWuueEVY5F3hi6IXW+nWt9UP29HNAZJSmnAmRjNQCkNgqV6kKIYrT\nmMVdKRUCbgPO1Vp3jrLa8cDLw97zFaXUR+zpBVhH8ZPWAG7WWrcgSO3aNVlfKYQQeSWbZpkPAzXA\nPUqpoXkrgLVa6/vt1w3A8BPLfwf8Win1afs7rhifuFmyr1I1W6S4CyGK05jFXWt9J3DnGOss3O/1\nDmDZ4UXL3dBA2a7dcpWqEKI4FdwVqvDWVareNinuQojiVKDFvcl67pCrVIUQxakgizv22TIl3TJQ\nthCiOBVmcff56AuGqOiVWxAIIYpTYRZ3oD9UTWV/F7FEyukoQggx6Qq2uMfCEYKJKL3t3U5HEUKI\nSVewxT1eY7W7x7bucDiJEEJMvoIt7umhWxDskAuZhBDFp2CLOw3WQNnpnS0OBxFCiMlXsMXd1WBd\npWq0ykDZQojiU7DF3dtsFXcZKFsIUYwKtriXzLCuUvW1y0DZQojiU7DF3ddkHbkHuuQqVSFE8SnY\n4k5ZOYO+EsrkFgRCiCJUuMUd6KuopqKvg0MZJ1YIIQpBQRf3gcoaKqK9DA7EnI4ihBCTqqCLe6w6\ngguTgW0ylqoQorhkM8weSqlbgVPs9W/RWt83bNkWYDswNEbqxVrrnUqp24ETARP4vNb6xXHMnZWU\nfQuC+LYWmH/EZH+9EEI4ZszirpRaBizQWi9RSlUDq4H79lvt3Vrr/mHvOQ2Ya79nHvBfwJJxzJ2V\n9NBA2TvlyF0IUVyyaZZ5BrjAnu4Ggkop9xjvOQP4E4DW+jUgrJSqyDlljowGa6DsjAyULYQoMtkM\nkJ0GBuyXVwDL7XnD/VwpNRP4O/A1oB5YNWx5mz2vd7TvCYdL8XjG2meMLhIpP2BeVM0CwNfZNuLy\nyeLkd49FsuVGsuVGsuUml2xZtbkDKKXOwyruZ+236JvAI0An1tH6h0Z4uzHW53d1RbONcoBIpJy2\ntr4D5ieqqq2Jll0jLp8Mo2XLB5ItN5ItN5ItN2NlG63wZ9uhejZwA3CO1rpn+DKt9V3D1lsOLARa\nsI7Uh0wDJr1tpHRmMwC+Nrm/jBCiuIzZ5q6UCgG3AedqrTv3X6aUelQp5bNnnQa8CjwGnG+vcyzQ\norWe9N2irzZCd3kVTZteJSnD7Qkhikg2R+4fBmqAe5RSQ/NWAGu11vfbR+vPK6UGsc6k+aPW2lRK\nrVJKPQtkgGsmIPvYDINdbz+Jec88yMYVz9J8zqmOxBBCiMmWTYfqncCdB1l+B3DHCPOvP7xo4yP9\nrrPgmQdJLH8YpLgLIYpEQV+hClD1/veSwaDmhWecjiKEEJOm4Iu7ty7C9hnzmLl1Pf275A6RQoji\nUPDFHaB7yal4Mmna/7zc6ShCCDEpiqK4+9/7bgA8Tz7hcBIhhJgcRVHcw6efTH+gjOY1/4eZyTgd\nRwghJlxRFHeX18u2BSdQ09NG+4svOx1HCCEmXFEUd4DY0tMBiD4g7e5CiMJXNMW98gPvA6Di7085\nnEQIISZe0RT38rkz2VE/ixlvrCHZ1z/2G4QQYgormuIOsOe4k/GnErQ9+LjTUYQQYkIVVXF3nX22\nNfHoo84GEUKICVZUxb3mvWcS8/qpe/HvTkcRQogJVVTF3V9Wyqa3HUt92zYG9Ean4wghxIQpquIO\n0HfyUgB67v+Ls0GEEGICFV1xD/7TewEIPP2kw0mEEGLiFF1xjxy3kNZwA83rXsRMJJyOI4QQE6Lo\nirvLMNjx9pMojUfpfvJvTscRQogJke0A2bcCp9jr36K1vm/YsmXALUAa0MCVwKnAH4B19mprtdaf\nG8fchyW17ExYcS/xB5fDu89wOo4QQoy7MYu7XbwXaK2XKKWqscZJvW/YKncCy7TWO5RSfwDOAaLA\nX7XW509E6MNV8/5zSP6rh/Dzf3U6ihBCTIhsmmWeAS6wp7uBoFLKPWz5Yq31Dnu6Dagex3wTIlRX\nzcZZC2javoHUrlan4wghxLgzTNPMemWl1FXAKVrrS0ZY1gD8DTgBWAj8DHgTqAJu0lof9Jr/VCpt\nejzug60yrv5x2Zd4x//czpZbf8rMf/7MpH2vEEKMM2OkmVm1uQMopc4DrgDOGmFZLfAX4DNa6w6l\n1BvATcA9wGzgKaXUEVrrUU9P6eqKZhvlAJFIOW1tfYf2pne9C/7nduIPPEjbZQfsq8ZNTtkmiWTL\njWTLjWTLzVjZIpHyEedn26F6NnADcI7Wume/ZRXAw8ANWuvHALTWO4G77VU2KqVagUZgczbfNxka\nl55IZ7CKaaufI5bJgKvoThwSQhSwMSuaUioE3Aacq7XuHGGV7wO3a60fGfaei5VS19nT9UAdsHN8\nIo8Pn8/DpgUnUD7QzeALK52OI4QQ4yqbI/cPAzXAPUqpoXkrgLXAo8DHgblKqSvtZb8Dfg/8zm7K\n8QFXH6xJxinR006HFx5m8A/3UrLkHU7HEUKIcTNmcdda34l1uuNo/KPMf19OiSZR+IIP0HfHTTTd\n91ui3/oGlJU5HUkIIcZFUTc018+o5R9nXEgw2kv/j//D6ThCCDFuirq4A5T/8xeIegNU/9fPIBZz\nOo4QQoyLoi/us46ayfOnfICKng6id/7S6ThCCDEuir64A/i+/EXibh8V//EjSCadjiOEEIdNijvw\ntuMUz5/wbsIduxi86zdOxxFCiMMmxR0wDAPzS18m5XIT/NHtkMk4HUkIIQ6LFHfbvFOO5oVjzqR6\n1xYS99zrdBwhhDgsUtxtLsMgeu0XSRsuvD+4FQ7hhmpCCJFvpLgPs+DsE1k5/xRqt2hSyx92Oo4Q\nQuRMivswHreLrmu+YL343vfk6F0IMWVJcd/PovcvZdXcE2jQa0j/VUZqEkJMTVLc9+P1uNl9lTXc\na/o7tzicRgghciPFfQQLLnoPa2csovHl58j840Wn4wghxCGT4j6CEr+HbZ/4LACJb3/H4TRCCHHo\npLiPYv5lH0RPUzQ/vwLWrHY6jhBCHBIp7qMoK/Xx+mXXAuD+1FUQjzucSAghspftGKq3AqfY69+i\ntb5v2LIzge8CaWC51vpme/7twImACXxeaz3lGq8Xfeoinlr+AMvWPMqeb92E8Z3vOh1JCCGyks0Y\nqsuABVrrJcA5wA/3W+VHwIeAdwJnKaXmK6VOA+ba77nCXmfKKSvxkvzev9EaqqPmP3+G+/nnnI4k\nhBBZyaZZ5hngAnu6GwgqpdwASqnZQKfWervWOgMsB86wH38C0Fq/BoSVUhXjHX4yvP3Y2Sy/6kYw\nTbxXXQn9/U5HEkKIMY1Z3LXWaa31gP3yCqyml7T9uh5oG7b6HqBhhPlt9rwp6bTPXMCDSz5Ieet2\n3F/7qtNxhBBiTFm1uQMopc7DKu5nHWQ14xDn7xUOl+LxuLONc4BIpDzn94792dBy+7+x+dxVzLr7\n12QuvhDX+87Ni2yHS7LlRrLlRrLlJpds2Xaong3cAJyjte4ZtqiFfY/IG+15if3mTwN2Hew7urqi\n2UQZUSRSTltbX87vz4aaFeEPn7qRq753JalLL2Pg2ZWY1dV5kS1Xki03ki03ki03Y2UbrfBn06Ea\nAm4DztVadw5fprXeAlQopWYqpTzAucBj9uN8+/3HAi1a6/zcclkyDIOzr3gv95z6MUq6OvB94XNy\nYzEhRN7K5sj9w0ANcI9SamjeCmCt1vp+4Grg9/b8u7XWG4ANSqlVSqlngQxwzfjGdkaozE/Z17/C\nug0vcNSjD9Lzx7tJXHCR07GEEOIAhpknR59tbX05B5nMn1SmaXLXzx/hM9++FI/PS9/fXyDT2JQX\n2Q6VZMuNZMuNZMtNFs0yI/ZpyhWqh8gwDP7pY6dz15mfxDfQR+Azn4JUyulYQgixDynuOQiX+6n9\n4md4YfbxBJ/7G2XXXCUFXgiRV6S45+jko6ex/OqbWT9tHiX3/5Hyq6+UAi+EyBtS3HNkGAaXXXg8\nv7jqe6xrnEfgz/dR/ukrIJl0OpoQQkhxPxxlJV4+9/GT+OknbuHVxqMIPHA/FZ+6XAq8EMJxUtwP\nU6jMz7WXnsSPLv02rzQtwP/gn6n45GWQSDgdTQhRxKS4j4PqUIBrL13CDy/5Fi83L8S//C9UXHmp\nFHghhGOkuI+TunAp116yhB985EbWTD8a/yMPUXHFJTLIhxDCEVLcx1FjTZDPfexEbrvwm6yecQz+\nRx+G887D6OxwOpoQoshIcR9nM+rL+ezF7+DW87/BytnHwaOPEj79ZDwy0IcQYhJJcZ8ARzSGuPqi\n4/jeB2/gtydfjKt1F5UfeA+lt98G6fTYHyCEEIdJivsEmTcjzLUfPpYHT/so159/M/2hGoK33Ezo\nwg/g2t3qdDwhRIGT4j6B5s0I8/0vnErX0cfzqQ/fxvqF78T3t6cJLzsJ74onnI4nhChgUtwn2LSa\nMm645DhmHjWLr555Hf/73quhp4fKiz5I8FvflAuehBATQor7JCgNePj8+Ys4+4Tp/FadzQ0fu41o\n80xKf/JDKt97Ju7X1jsdUQhRYKS4TxKXy+DDp8/l8vfM4/WaWVz+/lvYfMZ5eNesJnzmKVZnqxzF\nCyHGiRT3SXbyoga+8pFjcYcquPboT/CHa/+ddFU1wVtupvKc03Gve9XpiEKIApDtANkLgD8Dt2ut\nfzJsfiPw22GrzgauB3zAzcBGe/7jWuvvjEviAnBEU4hvXHo8P7l/LXe1HsFjl9zBv667h6aH7yV8\n1mlEv/jPRD//ZfB6nY4qhJiixizuSqkg8GPgyf2Xaa13Akvt9TzA08ADWINj3621vm4csxaU6lCA\nGy5ZzGMvbufPf9/M1fMu4cLZJ3LRvT8geOt38S1/kL47fkZ64SKnowohpqBsmmXiwHuAljHWuwy4\nV2vdf7ihioXH7eI9J87gW5e/gyOnV3KPfy5XfuR2Np3zIbyvvkL47KWUfe06XC07nY4qhJhish4g\nWyl1I9A+vFlmv+XPA2dprXuVUpcB1wAdgBe4Tmu9+mCfn0qlTY/HfQjRC0smY/L4P7bx3395lYFY\nivfH3uTSB3+CZ9sW8PngE5+A66+HmTOdjiqEyC8jDpCdVZv7WJRSS4DXtda99qzngTat9UP2sruA\nhQf7jK6uaM7fP5VHLh/u2DlVzLriBH77+Ab+tAEePv8HfC6+lnc+9D94fvELzF/+ktgFFxH9/JfJ\nzJ4zqdkmm2TLjWTLzVTOFomUjzh/vM6WORfYe8ml1vp1rfVD9vRzQEQpVbyH5YcgXO7nsx9cyDUf\nWECgLMC/+4/m05f+mLX/+gPSs+dQ8vvfUHXSYso/80ncb2xwOq4QIk+NV3E/Hnh56IVS6itKqY/Y\n0wuwjuLljlmHYLGq5bufPJGzjm+mrT/F1/tmc9Pn7mT7Hf+P9JHzCfzxbsInH0/oog/ie/ghGZxb\nCLGPbM6WWQx8H5gJJJVS52OdEbNZa32/vVoDsGfY234H/Fop9Wn7O64Yz9DFosTv4aIz5nLKogZ+\n+/gG1mzu4lp3He+56S4+2PcaFf/xI3wrnsC34gnSDdOIXfxxYh+7lMy0RqejCyEclnWH6kRra+vL\nOchUbi/Llmma/OO1Pfzvijfo6U9QEwrwkTPnsjixm9Jf/zf+e/4XV38fpstF4qx3M3jZ5SSXngGu\n0X+cFcN2mwiSLTeSLTdZtLmP2KEqV6hOEYZhcML8Or77yRM55x3T6eqL8+N713LTykH++omv0v7y\n6/T94MekFizC/8hDVF70IaqOX0Twpm/gWb0K8mQnLoSYHFLcp5gSv4cLTz+CGy9/B8e+LcKWXX38\n9P5X+frv1/HYwnfR9sjTdD32NIMfvQSjs5PSn95B+OxlVqG/8V/wvLRSCr0QRUCaZSbYRGfb1THA\nIy9s49lXW0lnTEJlPs46rpnTjmmk1Ezie3oF/gfux/fow7j6rRzp5unEzz2P0ks+QtuseeDOvxOZ\nivlvejgkW26mcrbRmmWkuE+wycrW1Rfn8ZXbeXr1TmKJNCV+N0vf3sgZxzZRVRGAWIx9Cn2fdUlC\npqaGxOnvIn7WOSSXno5ZEZrwrNmQv2luJFtupnI2Ke4Omexs0ViSp1bv5PGVO+gdSOAyDI5VEc5c\n3MTcphCGYUA8ju/pFYT++jjpvzyI2x72z/R4SJ54Eol3nUPiXWeTnnMEGCP+u5lw8jfNjWTLzVTO\nJsXdIU5lS6bSPL9+N0+s3MH2PdbtfqbXlXHm4mZOmF+L1+O2su3uwfPqK/geewTfE4/ifWnV3s9I\n19WTWnQ0qYVHk1p0DKlFR5NpbJqUgi9/09xIttxM5WxS3B3idDbTNNmwvZsnVu3gpQ1tmCaUlXhZ\n+vZpfPB0dcDFT8bu3fhWPI7/icfwvLQS984d+yzPVFXtLfbJk95J4qRToKRk3HM7vd0ORrLlRrLl\nRor7FP3DTKb2nkGeWr2TZ9a0MBCzivoRTSGOU7UsfluE6lDggPcY7e141r5sPV55Ge8ra3Bv2bx3\nuRkIkHjnKSTOPIvE6e8iM2v2uGTNp+22P8mWG8mWGynuU/QP44R4Ms0L63ezakM7r25q33tm5Oxp\nFVahVxEilaMfjRs93XjWrMb39Ap8Tz6G5/XX9i5LzZ5D4syzSC47g9TbjrSuls3hbJx83G5DJFtu\nJFtupLhP0T+MkyKRct7c0sHqDW2s1Ht4fWs3Gfvfw4z6ct5+RA1HzapiZkM57oNc6erasR3fk49b\nj2eexogO7F1mejxkpjWRnjGD9PQZZJqnk54+g/TMWaSPnIdZNvId7fJ9u0m2QyfZcpNrcR+XW/6K\nqSsU9LH07Y0sfXsjfdEEq99oZ6Xew2tbutja2sef/r6ZUr+HeTPDHDWriqNmVh1wVJ9paiZ26eXE\nLr0c4nG8LzyH9/+ewb11C+5t23Bt24rvb38d8fvT02eSmn+U9ThqAen5R5GeOT5NO0IUMzlyn2BT\nNdtALMlrW7pYt6WTdZs7ae+J7V1WGy7ZW+iPnF5JaSCLsV4HB3Hv2I572xZc27bh3vQmnvXr8axf\ni6ujY59VzZISjCOPJD6t2TrKnz6dzPQZpKfPJN08HUpLD+u/+3BN1b+p0yRbbuTIXYyrYMDLcUfW\nctyRtZimyZ7uQdZttgr9a1u7eOqlnTz10k4MA2Y3VDBvZhVHzQwzpzGExz1CE05JCem5byM99237\nzjdNjD178Ly2Ds/6dXjWv4pn3at4Xn8d/+qRB+/KRGpJNzWRqWsg09BApr6BdL31bD3qMSvDjp2j\nL0Q+kOIuxmQYBnXhUurCpZx+bBOpdIbNu3pZbx/Zb9rZy8aWXh58dgs+rwvVHGb+zDALZ1fTUF1q\nXTg1+odj1tWRrKsjufT0vbMjNWW0r9+Ee9sW3Nu24t62Fde2rbi3bsW9bQueda9irH5p1I81AwEy\ndfVk6urtwl9v7Qzq68k0TCM9azaZhmkHvWumEFOZFHdxyDxuF3ObKpnbVMl5J89iMJ5Cb+tm/ZZO\n1m/tYu2mDtZu6uDuFW9SEwqwaE41i+bUcOT0SnzeLM+cMQzM2lpStbWkjnvHgctNE6OrE9euXbh2\n78Ld2oprVwuu1lZcrS24drfiam3Fs/IfeDOZEb/CLC0lPWsOqSPmkp4zh/ScuaTnHEF6xizM0lLw\n+6X4iylLirs4bCV+D8fMreGYuTWAdZ+bdZs7eWVTB+s2d7DipZ2seGknXo+LeTPCLJpTzYJZVsfs\nQY/qD8YwMKuqSVdVkz5qAcnR1kuncbW34Wrdtbfgu1p24N60Efebb+LZ9CaedWtH/RrT78cMlGAG\nAhAIWM8V5YRKyzArQmRCIczyCsyKir3Tmbp60jNmkmlqBm8W/RFCTAAp7mLchcv9nLyogZMXNZBK\nZ9i4s4eXN3awdmMHr9gPgIDPTWNNkMZIGY2RIE01QRpry6go9Y1fGLd7b/PMiEwT164W3G++gXvj\nm7g3voF7xw6M2CDEYhixQYxw6tKoAAAOtElEQVTBGMRjGLGYdcO1LZvxxeNjfrXpdpNpbLZO+5wx\n036eAcEgpmEAhtUvMPzh8ZCpqyPd2AyBAy8qEyJbWRV3exzUPwO3a61/st+yLcB2YGiM1Iu11juV\nUrcDJwIm8Hmt9YvjFVpMHR63CzU9jJoe5sJlR9DePcjaTR3o7d3sbBtgS2sfG1t693lPRamX2U2V\nNNWUMrshxKxpFYSC41jwhzMMMtMayUxrJHnq0qzeEomU07ajHaO3F1dvN0ZPD0ZvL0ZvD66eHmtn\nsXUL7i2bcW3dgu+Zp3KKlq6tI9PcTLp5Opmm6aSbmsnU1kEmjRGPYyQSEI9jJBMQT2Ak4hAKEgiU\nk6muIVMTIVNTg1lTg1leIR3MRSabMVSDwI+BJw+y2ru11v3D3nMaMFdrvUQpNQ/4L2DJ4YYVU19N\nZQnLjm1i2bFNACRTGXZ3RtnR3s/OtgF2tg2wo62fNRvaWLPhrfdVVwSYPa2CWQ0VzJ5WQXNtGSV+\nB394+v2YkQjpSGTsdQcGrE7hrVtwb9sCsZjVZ2Ca1sApwx+pJO6WFlw7tuPevg3Py2vwrlp5SNFG\nuizM9PnIVNdgVlRg+gNW/kAA0+8Hf8BufgpgRmqtnUhTE+mm6aQbm6Cs7JC+X+SHbP7viAPvAb56\nCJ97BvAnAK31a0qpsFKqQmvdO8b7RJHxelw01ZbRVLtvAQkE/axc28Kmll427eplU0svL76+hxdf\nf2sc9opSL7VVpdSFS6yzeezp2nAJAV8etTgGg6TnzSc9b/6hvzedtvoKtm/HvX0rrvY2TK8PfD5M\nn88q0j4/+LyYPj+VQS+9G7fh6ujA1d6G0d6Gq6Pd6ndob8fVtgcjFofYIMYoHc37y4TDpBubyTQ2\ngteH6XLZzUjYz/ZrlwvT6wWPF7weTI8XvF5Mr8eaV1uF31+GWV391i+L6hoIBg99u4gxjfl/gNY6\nBaSUUgdb7edKqZnA34GvAfXAqmHL2+x5oxb3cLgUjyf3EYEikZEvY88Hki03y06YyTJ72jRNdndG\n2bCtC72tix27+2lp72fTzh7e3NFzwHvLS33UVAaoDpVQU1lCTWho2noOlfkpK/HicuXWVDGp262+\nEo4+MuvVK7JdMZWyfkXE49ZzNAqtrbB1K2zbZj1v3Ypr2zZcm96EV1/JKf6Y2UpKIBKBcNj6lRAM\nWs/Dp4NB8HjeGiJy/2ewOq/9frB3egc8253iBALWdw5/3d9PpNRlnR3lemtntXfa4SatXP69jcfh\nzTeBR4BOrKP1D42wzphbpqsrmnOAqXx1mZOmWjY3MK8pxLymt0aLSqUztHUPsrtrkD2dUXZ3DbK7\nK0pXX5yWtgE2t4z+Y9FlGJSVeCgv9VFe6qXMfg6V+qiqCFAdClATChAu9+9zYdZU225js34J4KuA\nyno48pgDVzFNjN4eSKasgprJYDCsOSmTsR7JJEYqZT8nreek9VzpNenbtB2jo936FdFhPYyODut5\n8xaM/r6sf1FMJrM0SKa21uqcr60jXVeHWVtHuq4es7YW0mmM7m5cPd0Y3d1W/0t3N0ZPN0av/W/Q\n7bZ+3Xg89rTb6vCvrqH/xm+P2vyVxRWqI84/7OKutb5raFoptRxYCLRgHakPmQbsOtzvEmJ/HreL\nhuogDdUH/rQ3TZPBeJquvhhdfXE6++J02Y++aIK+wSR90STd/XF2tg+M8OkWw4DKMr999B9gRkOI\nihIP9VWl1FeVOtv2P1kMAzNUuc+sQ75fSKSc2Fg7HtO0OokHBjCiA9bzQD/GwIC187CzHPBs91cY\niSQk4laHczL5VodzLI5hzycWw4hbv1iMeAwjFsdPmng8ae1YTBMyJpj2dDqN0d+Pa3crnhdfGPed\nj+nzMXj1NaTL5o7r5x7Wv0qlVAi4B3if1joBnAb8EdgJ3AT8Qil1LNCitc7PQx1RsAzDoDTgoTRQ\nRmPk4J2CqXSGfrvY9wzE6eyN094zSEdPjI6eGO29Md7c2cMbO3p4ft3ufd5bWeajoTq4t9hXVfgp\nDXgJBjyUBjwEA14CPnfu5/QXE8PYez2BWV09aV8biZTTm80vnnQao70d955WXHt249q9G9ee3Zhu\nD2ZlJZnKSsxQJWYoRCZUiVlZaZ2p5HJBOr33YaRT9nTG6tSegE7rbM6WWQx8H5gJJJVS5wMPAJu1\n1vfbR+vPK6UGgdXAH7XWplJqlVLqWSADXDPuyYUYRx63i8oyP5VlfpoZ+X+0VDpDd1+cuAmvb+qg\ntTNKa8cArZ1RXtvaxWtbu0b9fNfeHY2HyqDV7BMu91NVEaDKfg6X+ykv9cpOIJ+53Zh1daTq6g79\nvR6P9SCHXz05yKZDdRWw9CDL7wDuGGH+9YeVTIg843G7qKksIRIppzG8722P44k0u7ui7OqI0jOQ\nIBpLMhBLDXtOMWBPv9HVg8mBncBD31FV4ad6WNGvDgWoqvBTVR6gssxPwOfOuSNYFI8iaCwUYuL5\nfW6m15UzvW7ssxpS6Qzd/Vbbf2dvnM6+GF29Vp9AZ2+Mzr74QX8FAHjcBj6PG6/Xhd/jxud14fO6\nKQ/68LgMSv1Wc1BJwGM1D/mtXw2hoJ9IZSC72zSLKU2KuxCTzON2URMqoSY0+lCGyVTaLvZWwe/o\njdHZG6O7P0EimSaZyhBPZkik0iSSafoHkyRSaVLp7H7wBwMeK0NlgEhlCZFQgJrKEipKfXZfgZeA\n341LmoimLCnuQuQhr8e99zbLh6IyHGTbji6icaspKBpL7p0eiCXp7kvQ1jNIW/cgLR0DbN09eiei\nYbD3iH+og9jvdeP3uvF5rV8LQ9N++7XX7cLrGfZwu/B63Hg9LtIuF4l4SjqXJ4kUdyEKiNfjoiLo\noyKLe/GYpknPQIL27hht3YO09QzSH32rr2D4TmFX+wCJ1PicAuhxuygv9VJhX1cwdJ1Bqd+D1+uy\nmpvsnYPP89bOoazES0XQR3mWF5+l0hl6BxJ09yeIJVLWxWwVgaLpr5DiLkSRMgxj7xlCRwy7MGw0\nyZTVDBRPpEmkMsQTaeLJtD0vYzUXpTMkUxlS9nMyldk7D5dBW2fUusYgmmRX5wBbdx/6DsMwoLzE\nS0XQTyhoFfxgiZdoLEVPf5zugQQ9/Qn6Bw+8EbTH7aIuXGKdtlptnbpaV1WKy+ehdyCBy2XgMgzc\nLsO+QNV6PRV/aUhxF0JkZehoOphjZ+xIV1rGk+m9xX4wniKRypCydyKJ1Fs7iKF+hd6BBD0DCXoH\nEnT0DrKjrf+A7ynxewgFfTRFgoTK/ISCPvxeN209g7R2RGntjB70orWReNwGAZ+HgM+N3+cm4HNb\nr73WtMfjwu0ycLtcuN2GPW3gdrvwuA1KfJ69p8KW+r3Dpj0jD0s5DqS4CyEc4/e68Y/RuXwwiWSa\n3oEE/bEkpQHv3kJ+MEPNUa0dUVq7orR2RIklM0RjSTIZ03qY1nPafp1MZ4gl0sQTKbr74sQSadKZ\n8TlbvbLMx9cvWZzzNhiNFHchxJTl87qttnSyL4zDm6OOnBEGDv2ePKZpkkpnGEykrUKfzpBOWzuD\nVOat6XQmQyptEouniMZTDMRSDMZSRONJuz8jhdv+VTDepLgLIcQhMgzD7uh1U3FoJzRNGhn9Vwgh\nCpAUdyGEKEBS3IUQogBJcRdCiAIkxV0IIQqQFHchhChAUtyFEKIASXEXQogCZJjmZAz4JIQQYjLJ\nkbsQQhQgKe5CCFGApLgLIUQBkuIuhBAFSIq7EEIUICnuQghRgKS4CyFEAZryg3UopW4HTgRM4PNa\n6xcdjgSAUmop8AdgnT1rrdb6c84lAqXUAuDPwO1a658opZqBXwNuYBdwidY6nifZfgUsBjrsVW7T\nWj/kULZbgVOw/n+5BXiR/Nlu+2f7J/JguymlSoFfAXVAALgZeJk82G6jZDufPNhuQ5RSJcCrdrYn\nyWG7Tekjd6XUacBcrfUS4ArgRw5H2t9ftdZL7YfThT0I/BjrH8qQbwE/1VqfArwJXJ5H2QC+Nmz7\nOVXYlwEL7H9j5wA/JH+220jZIA+2G/A+YKXW+jTgQuAH5Ml2GyUb5Md2G/IvQKc9ndN2m9LFHTgD\n+BOA1vo1IKyUqnA2Ut6KA+8BWobNWwo8YE//BThzkjMNGSlbvngGuMCe7gaC5M92GynbwUeHniRa\n67u11rfaL5uBHeTJdhslW95QSh0JzAeGdjBLyWG7TfVmmXpg1bDXbfa8XmfiHGC+UuoBoAq4SWv9\nuFNBtNYpIKWUGj47OOzn3R6gYdKDMWo2gM8qpb6Ele2zWut2B7KlgQH75RXAcuDsPNluI2VLkwfb\nbYhS6lmgCTgXeCIfttuQ/bJ9ifzZbt8HPgtcar/O6f/TqX7kvj/D6QDDvAHcBJyH9Uf6pVLK52yk\ng8qnbQdWG+P1WuvTgTXAjU6GUUqdh1VAP7vfIse3237Z8mq7aa1PwuoH+A37bivHt9t+2fJiuyml\nPg48p7XePMoqWW+3qV7cW7CO1IdMw+pwcJzWeqf988/UWm8EWoFGp3Ptp9/uuAErW940i2itn9Ra\nr7FfPgAsdCqLUups4Abg3VrrHvJou+2fLV+2m1Jqsd1hj53HA/Tlw3YbJdvafNhuwHuB85RSzwNX\nAt8gx39vU724P4bVy41S6ligRWvd52wki1LqYqXUdfZ0PVbP/E5nUx3gCeBD9vSHgEcczLIPpdS9\nSqnZ9sulWGcOOJEjBNwGnKu1HurgyovtNlK2fNluwKnAl+1MdUAZebLdGDnbL/Jhu2mtP6y1Pl5r\nfSLwn1hny+S03ab8LX+VUt/D+mNlgGu01i87HAkApVQ58DugEvBhtbkvdzDPYqy2vJlAEmtHczHW\nKWEBYCvwCa11Mk+y/Ri4HogC/Xa2PQ5kuwrrJ/qGYbMvxfofz+ntNlK2/8ZqnnF6u5UAv8TqsCzB\naqJcCdyF89ttpGz9wK04vN2GU0rdCGwBHiWH7Tbli7sQQogDTfVmGSGEECOQ4i6EEAVIirsQQhQg\nKe5CCFGApLgLIUQBkuIuhBAFSIq7EEIUoP8P4ic6tYMt7F4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4aa160b198>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.plot(test_losses, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0tVzzJ7D05L"
   },
   "source": [
    "# Evaluate text generation\n",
    "\n",
    "Check what the outputted text looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "4kFxF7_WD05M",
    "outputId": "8e01fae5-3586-42f4-d9fd-3efaad8dbda6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This naught her to the sleep!\n",
      "That shall been you thou yet to\n",
      "At the other to me, and to the duke to advances\n",
      "Marry be as much down.\n",
      "\n",
      "ROSSALINE:\n",
      "Ay, then I have room in a short, that a times.\n",
      "\n",
      "LYCAILUS:\n",
      "Full the cousin, being father in a words,\n",
      "The deed strings the serve with the company, see.\n",
      "Lord knee quarters in the properor and kind on my love\n",
      "That thus on her understand to comforth becomes\n",
      "to caintly have benefites shall be gone.\n",
      "\n",
      "POLPEY:\n",
      "O gain you sad to send upon all amends.\n",
      "\n",
      "PANEROLLES:\n",
      "Let him out of me so unpressips, we debered.\n",
      "\n",
      "DUKE SYRACUSE:\n",
      "If you shall be conceit his daughter in\n",
      "By help it. This is the godges of my wise;\n",
      "What are strength, here we stand understand this\n",
      "word off my slain! Can the thilk not twasty.\n",
      "\n",
      "DON PEDRO:\n",
      "Then blush and here on dog;\n",
      "For I, his wish'd, smoke the gods, my lords!\n",
      "How now, sir, and through that a farther, as the king\n",
      "That he lost like a devil, nor away,\n",
      "And let their father;' yet so besting that that\n",
      "sweer at much many consicial bring litt\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(rnn, prime_str='Th', predict_len=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuEcb1xJD05O"
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Some things you should try to improve your network performance are:\n",
    "- Different RNN types. Switch the basic RNN network in your model to a GRU and LSTM to compare all three.\n",
    "- Try adding 1 or two more layers\n",
    "- Increase the hidden layer size\n",
    "- Changing the learning rate\n",
    "\n",
    "**TODO:** Try changing the RNN type and hyperparameters. Record your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0xDcgMC3D05P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MP4_P2_generation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
